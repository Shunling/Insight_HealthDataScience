{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB, ComplementNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score,roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>provider_status</th>\n",
       "      <th>hmo_id</th>\n",
       "      <th>care_id</th>\n",
       "      <th>qty</th>\n",
       "      <th>amount</th>\n",
       "      <th>approved_qty</th>\n",
       "      <th>approved_amount</th>\n",
       "      <th>hmo_approved</th>\n",
       "      <th>created_at</th>\n",
       "      <th>vetted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1816.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1816.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-12 14:53:46</td>\n",
       "      <td>2018-05-21 10:05:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1816.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1816.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-13 14:50:39</td>\n",
       "      <td>2018-05-21 10:07:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-16 10:28:53</td>\n",
       "      <td>2018-05-21 10:09:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1265.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1265.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-16 10:28:53</td>\n",
       "      <td>2018-05-21 10:09:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-16 10:28:53</td>\n",
       "      <td>2018-05-21 10:09:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id  enrollee_id  provider_id  provider_status  hmo_id  care_id   qty  \\\n",
       "0      10.0         89.0          1.0              1.0     1.0    586.0   6.0   \n",
       "1      11.0         89.0          1.0              1.0     1.0    586.0   6.0   \n",
       "2      13.0         74.0          1.0              1.0     1.0    434.0   5.0   \n",
       "3      13.0         74.0          1.0              1.0     1.0   1102.0  10.0   \n",
       "4      13.0         74.0          1.0              1.0     1.0    299.0  15.0   \n",
       "\n",
       "    amount  approved_qty  approved_amount  hmo_approved           created_at  \\\n",
       "0  1816.08           6.0          1816.08           1.0  2018-03-12 14:53:46   \n",
       "1  1816.08           6.0          1816.08           1.0  2018-03-13 14:50:39   \n",
       "2   115.00           5.0           115.00           1.0  2018-03-16 10:28:53   \n",
       "3  1265.00          10.0          1265.00           1.0  2018-03-16 10:28:53   \n",
       "4   138.00          15.0           138.00           1.0  2018-03-16 10:28:53   \n",
       "\n",
       "             vetted_at  \n",
       "0  2018-05-21 10:05:30  \n",
       "1  2018-05-21 10:07:19  \n",
       "2  2018-05-21 10:09:30  \n",
       "3  2018-05-21 10:09:30  \n",
       "4  2018-05-21 10:09:30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Processed_data/claims.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 282380 entries, 0 to 319563\n",
      "Data columns (total 13 columns):\n",
      "claim_id           282380 non-null float64\n",
      "enrollee_id        282380 non-null float64\n",
      "provider_id        282380 non-null float64\n",
      "provider_status    282380 non-null float64\n",
      "hmo_id             282380 non-null float64\n",
      "care_id            282380 non-null float64\n",
      "qty                282380 non-null float64\n",
      "amount             282380 non-null float64\n",
      "approved_qty       282380 non-null float64\n",
      "approved_amount    282380 non-null float64\n",
      "hmo_approved       282380 non-null float64\n",
      "created_at         282380 non-null object\n",
      "vetted_at          282380 non-null object\n",
      "dtypes: float64(11), object(2)\n",
      "memory usage: 30.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset = ['claim_id','enrollee_id','vetted_at'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_id\n",
      "10.0 64512.0\n",
      "enrollee_id\n",
      "1.0 151730.0\n",
      "provider_id\n",
      "1.0 426.0\n",
      "provider_status\n",
      "1.0 1.0\n",
      "hmo_id\n",
      "1.0 5.0\n",
      "care_id\n",
      "2.0 88485.0\n",
      "qty\n",
      "-30.0 15000.0\n",
      "amount\n",
      "-17475.0 2850000.0\n",
      "approved_qty\n",
      "-30.0 12000.0\n",
      "approved_amount\n",
      "-17475.0 2850000.0\n",
      "hmo_approved\n",
      "-1.0 1.0\n",
      "created_at\n",
      "2018-03-12 14:53:46 2020-01-10 11:50:15\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns[:-1]:\n",
    "    print(col)\n",
    "    print(df[col].min(),df[col].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 282055 entries, 0 to 319563\n",
      "Data columns (total 14 columns):\n",
      "claim_id           282055 non-null float64\n",
      "enrollee_id        282055 non-null float64\n",
      "provider_id        282055 non-null float64\n",
      "provider_status    282055 non-null float64\n",
      "hmo_id             282055 non-null float64\n",
      "care_id            282055 non-null float64\n",
      "qty                282055 non-null float64\n",
      "amount             282055 non-null float64\n",
      "approved_qty       282055 non-null float64\n",
      "approved_amount    282055 non-null float64\n",
      "hmo_approved       282055 non-null float64\n",
      "created_at         282055 non-null object\n",
      "vetted_at          282055 non-null object\n",
      "unite_price        282055 non-null float64\n",
      "dtypes: float64(12), object(2)\n",
      "memory usage: 32.3+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df = df.loc[(df['qty']>0) & (df['hmo_id'] != 0)]\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_id\n",
      "10.0 64512.0\n",
      "enrollee_id\n",
      "1.0 151730.0\n",
      "provider_id\n",
      "1.0 426.0\n",
      "provider_status\n",
      "1.0 1.0\n",
      "hmo_id\n",
      "1.0 5.0\n",
      "care_id\n",
      "2.0 88485.0\n",
      "qty\n",
      "1.0 15000.0\n",
      "amount\n",
      "0.0 2850000.0\n",
      "approved_qty\n",
      "0.0 12000.0\n",
      "approved_amount\n",
      "0.0 2850000.0\n",
      "hmo_approved\n",
      "-1.0 1.0\n",
      "created_at\n",
      "2018-03-12 14:53:46 2020-01-10 11:50:15\n"
     ]
    }
   ],
   "source": [
    "for col in clean_df.columns[:-2]:\n",
    "    print(col)\n",
    "    print(clean_df[col].min(),clean_df[col].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shunling/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "clean_df['unite_price'] = clean_df['amount']/clean_df['qty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 2850000.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['unite_price'].min(),clean_df['unite_price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df[['enrollee_id','provider_id','provider_status','hmo_id','care_id','qty','unite_price']]\n",
    "# the approved cases are True, and would be classified as 0\n",
    "y = (clean_df['hmo_approved'] == 1) & (clean_df['approved_amount'] == clean_df['amount'])\n",
    "y = y.map({True:0,False:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((282055, 7), (282055,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test spilt\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X.values,y.values,test_size = 0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214483, 11161, 19.217184840068093)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ytrain == 0).sum(),(ytrain == 1).sum(),(ytrain == 0).sum()/(ytrain == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53654, 2757, 19.46100834240116)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ytest == 0).sum(),(ytest == 1).sum(),(ytest == 0).sum()/(ytest == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_scores():\n",
    "    \n",
    "    global scores \n",
    "    scores = {}\n",
    "    scores['f1_socre'] = []\n",
    "    scores['precision'] = []\n",
    "    scores['recall'] = []\n",
    "    scores['FPR'] = []\n",
    "    scores['specificity'] = []\n",
    "    scores['roc_auc'] = []\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def evaluation(ytest,Xtest,cls):\n",
    "    global scores\n",
    "    scores = init_scores()\n",
    "    ypred = cls.predict(Xtest)\n",
    "    C = confusion_matrix(ytest,ypred)\n",
    "    TN = C[0][0]\n",
    "    FN = C[1][0]\n",
    "    TP = C[1][1]\n",
    "    FP = C[0][1]\n",
    "\n",
    "    print('f1_socre: {:0.3f}'.format(f1_score(ytest,ypred)))\n",
    "    scores['f1_socre'].append(f1_score(ytest,ypred))\n",
    "    print('precision: {:0.3f}'.format(TP/(TP+FP)))\n",
    "    scores['precision'].append(TP/(TP+FP))\n",
    "    print('recall/sensitivity(true positive rate): {:0.3f}'.format(TP/(TP+FN)))\n",
    "    scores['recall'].append(TP/(TP+FN))\n",
    "    print('false positive rate (FPR): {:0.3f}'.format(1-(TN/(TN+FP)))) # 1 - specificity\n",
    "    scores['FPR'].append(1-(TN/(TN+FP)))\n",
    "    print('spcificity(true negative rate): {:0.3f}'.format(TN/(TN+FP)))\n",
    "    scores['specificity'].append(TN/(TN+FP))\n",
    "    print('ROC_AUC_score: {:0.3f}'.format(roc_auc_score(ytest,ypred)))\n",
    "    scores['roc_auc'].append(roc_auc_score(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cv(Xtrain,ytrain,model):\n",
    "    global scores\n",
    "    models = []\n",
    "    kf = KFold(n_splits=4)\n",
    "    print(model)\n",
    "    n = 0\n",
    "    for train_index, test_index in kf.split(Xtrain):\n",
    "        print('cross_validate_run: {}'.format(n))\n",
    "        Xtr, Xte = Xtrain[train_index], Xtrain[test_index]\n",
    "        ytr, yte = ytrain[train_index], ytrain[test_index]\n",
    "        cls = model.fit(Xtr, ytr) \n",
    "        models.append(cls)\n",
    "        evaluation(yte,Xte,cls)\n",
    "        n += 1\n",
    "    \n",
    "    print('\\n mean scores +/- sd: \\n')\n",
    "    for k in scores:\n",
    "        print('{} : {:0.3f} +/- {:0.3f}'.format(k, np.array(scores[k]).mean(),  np.array(scores[k]).std()))\n",
    "        \n",
    "    scores = init_scores()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)\n",
      "cross_validate_run: 0\n",
      "f1_socre: 0.104\n",
      "precision: 0.060\n",
      "recall/sensitivity(true positive rate): 0.387\n",
      "false positive rate (FPR): 0.313\n",
      "spcificity(true negative rate): 0.687\n",
      "ROC_AUC_score: 0.537\n",
      "cross_validate_run: 1\n",
      "f1_socre: 0.109\n",
      "precision: 0.063\n",
      "recall/sensitivity(true positive rate): 0.397\n",
      "false positive rate (FPR): 0.314\n",
      "spcificity(true negative rate): 0.686\n",
      "ROC_AUC_score: 0.542\n",
      "cross_validate_run: 2\n",
      "f1_socre: 0.104\n",
      "precision: 0.060\n",
      "recall/sensitivity(true positive rate): 0.396\n",
      "false positive rate (FPR): 0.314\n",
      "spcificity(true negative rate): 0.686\n",
      "ROC_AUC_score: 0.541\n",
      "cross_validate_run: 3\n",
      "f1_socre: 0.107\n",
      "precision: 0.062\n",
      "recall/sensitivity(true positive rate): 0.385\n",
      "false positive rate (FPR): 0.306\n",
      "spcificity(true negative rate): 0.694\n",
      "ROC_AUC_score: 0.540\n",
      "\n",
      " mean scores +/- sd: \n",
      "\n",
      "f1_socre : 0.107 +/- 0.000\n",
      "precision : 0.062 +/- 0.000\n",
      "recall : 0.385 +/- 0.000\n",
      "FPR : 0.306 +/- 0.000\n",
      "specificity : 0.694 +/- 0.000\n",
      "roc_auc : 0.540 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "model1 = ComplementNB()\n",
    "models_nb1 = cv(Xtrain,ytrain,model1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_socre: 0.108\n",
      "precision: 0.063\n",
      "recall/sensitivity(true positive rate): 0.404\n",
      "false positive rate (FPR): 0.311\n",
      "spcificity(true negative rate): 0.689\n",
      "ROC_AUC_score: 0.547\n"
     ]
    }
   ],
   "source": [
    "evaluation(ytest,Xtest,models_nb1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "cross_validate_run: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2500000 is out of bounds for axis 1 with size 2200001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-75642195b0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-98f6bac4637c>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(Xtrain, ytrain, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myte\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXte\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-6617cd9b10a4>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(ytest, Xtest, cls)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mTN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m             \u001b[0mjll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m         \u001b[0mtotal_ll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjll\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_log_prior_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_ll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2500000 is out of bounds for axis 1 with size 2200001"
     ]
    }
   ],
   "source": [
    "model2 = CategoricalNB()\n",
    "cv(Xtrain,ytrain,model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=19, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "cross_validate_run: 0\n",
      "f1_socre: 0.245\n",
      "precision: 0.148\n",
      "recall/sensitivity(true positive rate): 0.699\n",
      "false positive rate (FPR): 0.208\n",
      "spcificity(true negative rate): 0.792\n",
      "ROC_AUC_score: 0.746\n",
      "cross_validate_run: 1\n",
      "f1_socre: 0.254\n",
      "precision: 0.155\n",
      "recall/sensitivity(true positive rate): 0.706\n",
      "false positive rate (FPR): 0.205\n",
      "spcificity(true negative rate): 0.795\n",
      "ROC_AUC_score: 0.750\n",
      "cross_validate_run: 2\n",
      "f1_socre: 0.247\n",
      "precision: 0.149\n",
      "recall/sensitivity(true positive rate): 0.716\n",
      "false positive rate (FPR): 0.207\n",
      "spcificity(true negative rate): 0.793\n",
      "ROC_AUC_score: 0.754\n",
      "cross_validate_run: 3\n",
      "f1_socre: 0.246\n",
      "precision: 0.149\n",
      "recall/sensitivity(true positive rate): 0.698\n",
      "false positive rate (FPR): 0.209\n",
      "spcificity(true negative rate): 0.791\n",
      "ROC_AUC_score: 0.744\n",
      "\n",
      " mean scores +/- sd: \n",
      "\n",
      "f1_socre : 0.246 +/- 0.000\n",
      "precision : 0.149 +/- 0.000\n",
      "recall : 0.698 +/- 0.000\n",
      "FPR : 0.209 +/- 0.000\n",
      "specificity : 0.791 +/- 0.000\n",
      "roc_auc : 0.744 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "model3 = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=19, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "models_xgb = cv(Xtrain,ytrain,model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_socre: 0.249\n",
      "precision: 0.151\n",
      "recall/sensitivity(true positive rate): 0.715\n",
      "false positive rate (FPR): 0.207\n",
      "spcificity(true negative rate): 0.793\n",
      "ROC_AUC_score: 0.754\n"
     ]
    }
   ],
   "source": [
    "evaluation(ytest,Xtest,models_xgb[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(model5,open(\"Models/xgb1.dat\", \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
