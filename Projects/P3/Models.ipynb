{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB, ComplementNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score,roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>provider_status</th>\n",
       "      <th>hmo_id</th>\n",
       "      <th>care_id</th>\n",
       "      <th>qty</th>\n",
       "      <th>amount</th>\n",
       "      <th>approved_qty</th>\n",
       "      <th>approved_amount</th>\n",
       "      <th>hmo_approved</th>\n",
       "      <th>created_at</th>\n",
       "      <th>vetted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1816.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1816.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-12 14:53:46</td>\n",
       "      <td>2018-05-21 10:05:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1816.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1816.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-13 14:50:39</td>\n",
       "      <td>2018-05-21 10:07:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-16 10:28:53</td>\n",
       "      <td>2018-05-21 10:09:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1265.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1265.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-16 10:28:53</td>\n",
       "      <td>2018-05-21 10:09:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-16 10:28:53</td>\n",
       "      <td>2018-05-21 10:09:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id  enrollee_id  provider_id  provider_status  hmo_id  care_id   qty  \\\n",
       "0      10.0         89.0          1.0              1.0     1.0    586.0   6.0   \n",
       "1      11.0         89.0          1.0              1.0     1.0    586.0   6.0   \n",
       "2      13.0         74.0          1.0              1.0     1.0    434.0   5.0   \n",
       "3      13.0         74.0          1.0              1.0     1.0   1102.0  10.0   \n",
       "4      13.0         74.0          1.0              1.0     1.0    299.0  15.0   \n",
       "\n",
       "    amount  approved_qty  approved_amount  hmo_approved           created_at  \\\n",
       "0  1816.08           6.0          1816.08           1.0  2018-03-12 14:53:46   \n",
       "1  1816.08           6.0          1816.08           1.0  2018-03-13 14:50:39   \n",
       "2   115.00           5.0           115.00           1.0  2018-03-16 10:28:53   \n",
       "3  1265.00          10.0          1265.00           1.0  2018-03-16 10:28:53   \n",
       "4   138.00          15.0           138.00           1.0  2018-03-16 10:28:53   \n",
       "\n",
       "             vetted_at  \n",
       "0  2018-05-21 10:05:30  \n",
       "1  2018-05-21 10:07:19  \n",
       "2  2018-05-21 10:09:30  \n",
       "3  2018-05-21 10:09:30  \n",
       "4  2018-05-21 10:09:30  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('Processed_data/claims.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 323140 entries, 0 to 323148\n",
      "Data columns (total 13 columns):\n",
      "claim_id           323140 non-null float64\n",
      "enrollee_id        323140 non-null float64\n",
      "provider_id        323140 non-null float64\n",
      "provider_status    323140 non-null float64\n",
      "hmo_id             323140 non-null float64\n",
      "care_id            323140 non-null float64\n",
      "qty                323140 non-null float64\n",
      "amount             323140 non-null float64\n",
      "approved_qty       323140 non-null float64\n",
      "approved_amount    323140 non-null float64\n",
      "hmo_approved       323140 non-null float64\n",
      "created_at         323140 non-null object\n",
      "vetted_at          282380 non-null object\n",
      "dtypes: float64(11), object(2)\n",
      "memory usage: 34.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop cases without claim_id and enrollee_id\n",
    "df.dropna(subset = ['claim_id','enrollee_id'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_id\n",
      "10.0 65243.0\n",
      "enrollee_id\n",
      "1.0 153580.0\n",
      "provider_id\n",
      "1.0 436.0\n",
      "provider_status\n",
      "0.0 1.0\n",
      "hmo_id\n",
      "1.0 5.0\n",
      "care_id\n",
      "2.0 91038.0\n",
      "qty\n",
      "-60.0 15000.0\n",
      "amount\n",
      "-48000.0 2850000.0\n",
      "approved_qty\n",
      "-60.0 12000.0\n",
      "approved_amount\n",
      "-48000.0 2850000.0\n",
      "hmo_approved\n",
      "-1.0 1.0\n",
      "created_at\n",
      "2018-03-12 14:53:46 2020-01-16 17:30:50\n"
     ]
    }
   ],
   "source": [
    "# check value range\n",
    "for col in df.columns[:-1]:\n",
    "    print(col)\n",
    "    print(df[col].min(),df[col].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop negative cases\n",
    "clean_df = df.drop(df.loc[df['qty'] < 0].index,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_id\n",
      "10.0 65243.0\n",
      "enrollee_id\n",
      "1.0 153580.0\n",
      "provider_id\n",
      "1.0 436.0\n",
      "provider_status\n",
      "0.0 1.0\n",
      "hmo_id\n",
      "1.0 5.0\n",
      "care_id\n",
      "2.0 91038.0\n",
      "qty\n",
      "0.0 15000.0\n",
      "amount\n",
      "0.0 2850000.0\n",
      "approved_qty\n",
      "0.0 12000.0\n",
      "approved_amount\n",
      "-1.0 2850000.0\n",
      "hmo_approved\n",
      "-1.0 1.0\n",
      "created_at\n",
      "2018-03-12 14:53:46 2020-01-16 17:30:50\n"
     ]
    }
   ],
   "source": [
    "# check again\n",
    "for col in clean_df.columns[:-1]:\n",
    "    print(col)\n",
    "    print(clean_df[col].min(),clean_df[col].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check untouched cases, could used as testing cases\n",
    "testing_cases = clean_df.loc[clean_df['hmo_approved'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282371, 13)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unprocessed cases\n",
    "clean_df = clean_df.loc[clean_df['hmo_approved'] != 0]\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 282371 entries, 0 to 319563\n",
      "Data columns (total 13 columns):\n",
      "claim_id           282371 non-null float64\n",
      "enrollee_id        282371 non-null float64\n",
      "provider_id        282371 non-null float64\n",
      "provider_status    282371 non-null float64\n",
      "hmo_id             282371 non-null float64\n",
      "care_id            282371 non-null float64\n",
      "qty                282371 non-null float64\n",
      "amount             282371 non-null float64\n",
      "approved_qty       282371 non-null float64\n",
      "approved_amount    282371 non-null float64\n",
      "hmo_approved       282371 non-null float64\n",
      "created_at         282371 non-null object\n",
      "vetted_at          282371 non-null object\n",
      "dtypes: float64(11), object(2)\n",
      "memory usage: 30.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose features for X\n",
    "X = clean_df[['enrollee_id','provider_id','provider_status','hmo_id','care_id','qty','amount']]\n",
    "\n",
    "# the approved cases are True, and would be classified as 0, we consider problematic cases to be positive\n",
    "y = (clean_df['hmo_approved'] == 1) & (clean_df['approved_amount'] == clean_df['amount'])\n",
    "y = y.map({True:0,False:1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((282371, 7), (282371,))"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test spilt\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X.values,y.values,test_size = 0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214788, 11108, 19.3363341735686)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data unbalance for training data\n",
    "(ytrain == 0).sum(),(ytrain == 1).sum(),(ytrain == 0).sum()/(ytrain == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53663, 2812, 19.08357041251778)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data unbalance for testing data\n",
    "(ytest == 0).sum(),(ytest == 1).sum(),(ytest == 0).sum()/(ytest == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(ytest,Xtest,cls):\n",
    "    \"\"\"\n",
    "    model evaluation function:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ypred = cls.predict(Xtest)\n",
    "    C = confusion_matrix(ytest,ypred)\n",
    "    TN = C[0][0] # true negatives\n",
    "    FN = C[1][0] # false negatives\n",
    "    TP = C[1][1] # true positives \n",
    "    FP = C[0][1] # false positives\n",
    "\n",
    "    print('f1_socre: {:1f}'.format(f1_score(ytest,ypred)))\n",
    "    print('precision: {:1f}'.format((TP)/(TP+FP)))\n",
    "    print('recall/sensitivity(true positive rate): {:1f}'.format((TP)/(TP+FN)))\n",
    "    print('spcificity(true negative rate): {:1f}'.format(TN/(TN+FP)))\n",
    "    print('false positive rate (FPR): {:1f}'.format(1-(TN/(TN+FP)))) # 1 - specificity\n",
    "    print('ROC_AUC_score: {:1f}'.format(roc_auc_score(ytest,ypred))) # area under curve\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(Xtrain,ytrain,model):\n",
    "    \n",
    "    \"\"\"\n",
    "    4-fold cross validation\n",
    "    \"\"\"\n",
    "    \n",
    "    models = []\n",
    "    kf = KFold(n_splits=4)\n",
    "    print(model)\n",
    "    n = 0\n",
    "    for train_index, test_index in kf.split(Xtrain):\n",
    "        print('cross_validate_run: {}'.format(n))\n",
    "        Xtr, Xte = Xtrain[train_index], Xtrain[test_index]\n",
    "        ytr, yte = ytrain[train_index], ytrain[test_index]\n",
    "        cls = model.fit(Xtr, ytr) \n",
    "        models.append(cls)\n",
    "        evaluation(yte,Xte,cls)\n",
    "        n += 1\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)\n",
      "cross_validate_run: 0\n",
      "f1_socre: 0.124268\n",
      "precision: 0.074684\n",
      "recall/sensitivity(true positive rate): 0.369745\n",
      "spcificity(true negative rate): 0.762549\n",
      "false positive rate (FPR): 0.237451\n",
      "ROC_AUC_score: 0.566147\n",
      "cross_validate_run: 1\n",
      "f1_socre: 0.122076\n",
      "precision: 0.074156\n",
      "recall/sensitivity(true positive rate): 0.345055\n",
      "spcificity(true negative rate): 0.781166\n",
      "false positive rate (FPR): 0.218834\n",
      "ROC_AUC_score: 0.563111\n",
      "cross_validate_run: 2\n",
      "f1_socre: 0.126061\n",
      "precision: 0.077524\n",
      "recall/sensitivity(true positive rate): 0.337147\n",
      "spcificity(true negative rate): 0.790953\n",
      "false positive rate (FPR): 0.209047\n",
      "ROC_AUC_score: 0.564050\n",
      "cross_validate_run: 3\n",
      "f1_socre: 0.123961\n",
      "precision: 0.076003\n",
      "recall/sensitivity(true positive rate): 0.335954\n",
      "spcificity(true negative rate): 0.787093\n",
      "false positive rate (FPR): 0.212907\n",
      "ROC_AUC_score: 0.561524\n"
     ]
    }
   ],
   "source": [
    "# choose complement naive bayes to handle imbalanced data\n",
    "model1 = ComplementNB()\n",
    "models = cv(Xtrain,ytrain,model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_socre: 0.122000\n",
      "precision: 0.075074\n",
      "recall/sensitivity(true positive rate): 0.325391\n",
      "spcificity(true negative rate): 0.789930\n",
      "false positive rate (FPR): 0.210070\n",
      "ROC_AUC_score: 0.557660\n"
     ]
    }
   ],
   "source": [
    "# evaluate test data\n",
    "evaluation(ytest,Xtest,models[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "cross_validate_run: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 88485 is out of bounds for axis 1 with size 87559",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-264-75642195b0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-227-0e3650be7206>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(Xtrain, ytrain, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myte\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXte\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-261-3e29d92d6004>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(ytest, Xtest, cls)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mTN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m             \u001b[0mjll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m         \u001b[0mtotal_ll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjll\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_log_prior_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_ll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 88485 is out of bounds for axis 1 with size 87559"
     ]
    }
   ],
   "source": [
    "# categorical naive bayes to hanle categorical data\n",
    "model2 = CategoricalNB()\n",
    "cv(Xtrain,ytrain,model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=19, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "cross_validate_run: 0\n",
      "f1_socre: 0.247212\n",
      "precision: 0.149885\n",
      "recall/sensitivity(true positive rate): 0.704995\n",
      "spcificity(true negative rate): 0.792740\n",
      "false positive rate (FPR): 0.207260\n",
      "ROC_AUC_score: 0.748867\n",
      "cross_validate_run: 1\n",
      "f1_socre: 0.249840\n",
      "precision: 0.151430\n",
      "recall/sensitivity(true positive rate): 0.713553\n",
      "spcificity(true negative rate): 0.796889\n",
      "false positive rate (FPR): 0.203111\n",
      "ROC_AUC_score: 0.755221\n",
      "cross_validate_run: 2\n",
      "f1_socre: 0.246877\n",
      "precision: 0.150213\n",
      "recall/sensitivity(true positive rate): 0.692528\n",
      "spcificity(true negative rate): 0.795853\n",
      "false positive rate (FPR): 0.204147\n",
      "ROC_AUC_score: 0.744190\n",
      "cross_validate_run: 3\n",
      "f1_socre: 0.248233\n",
      "precision: 0.151947\n",
      "recall/sensitivity(true positive rate): 0.677627\n",
      "spcificity(true negative rate): 0.802854\n",
      "false positive rate (FPR): 0.197146\n",
      "ROC_AUC_score: 0.740241\n"
     ]
    }
   ],
   "source": [
    "# xgboost: use scale_pos_weight to handle imbalanced data\n",
    "model3 = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=19, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "models_xgb = cv(Xtrain,ytrain,model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_socre: 0.254277\n",
      "precision: 0.155205\n",
      "recall/sensitivity(true positive rate): 0.703058\n",
      "spcificity(true negative rate): 0.799471\n",
      "false positive rate (FPR): 0.200529\n",
      "ROC_AUC_score: 0.751265\n"
     ]
    }
   ],
   "source": [
    "# evaluate testing data\n",
    "evaluation(ytest,Xtest,models_xgb[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(model5,open(\"Models/xgb1.dat\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use upsampling training sample to handle data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268451, 8) (13920, 8)\n"
     ]
    }
   ],
   "source": [
    "# upsampling of positive data input\n",
    "Xy = X.copy()\n",
    "Xy['y'] = y\n",
    "\n",
    "class0 = Xy.loc[Xy.y == 0]\n",
    "class1 = Xy.loc[Xy.y == 1]\n",
    "print(class0.shape,class1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = class1.sample(n=class0.shape[0],replace=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.concat([class0,class1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "yup = Xy['y']\n",
    "Xup = Xy.drop(columns=['y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268451, 268451)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(yup == 0).sum(),(yup == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-do train_test split of balanced data\n",
    "Xuptrain,Xuptest,yuptrain,yuptest = train_test_split(Xup.values,yup.values,test_size = 0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)\n",
      "cross_validate_run: 0\n",
      "f1_socre: 0.444746\n",
      "precision: 0.614243\n",
      "recall/sensitivity(true positive rate): 0.348562\n",
      "spcificity(true negative rate): 0.781247\n",
      "false positive rate (FPR): 0.218753\n",
      "ROC_AUC_score: 0.564904\n",
      "cross_validate_run: 1\n",
      "f1_socre: 0.446745\n",
      "precision: 0.615089\n",
      "recall/sensitivity(true positive rate): 0.350749\n",
      "spcificity(true negative rate): 0.778957\n",
      "false positive rate (FPR): 0.221043\n",
      "ROC_AUC_score: 0.564853\n",
      "cross_validate_run: 2\n",
      "f1_socre: 0.442127\n",
      "precision: 0.612476\n",
      "recall/sensitivity(true positive rate): 0.345916\n",
      "spcificity(true negative rate): 0.781280\n",
      "false positive rate (FPR): 0.218720\n",
      "ROC_AUC_score: 0.563598\n",
      "cross_validate_run: 3\n",
      "f1_socre: 0.441999\n",
      "precision: 0.612328\n",
      "recall/sensitivity(true positive rate): 0.345807\n",
      "spcificity(true negative rate): 0.781310\n",
      "false positive rate (FPR): 0.218690\n",
      "ROC_AUC_score: 0.563559\n"
     ]
    }
   ],
   "source": [
    "models_nb_up = cv(Xuptrain,yuptrain,model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_socre: 0.443734\n",
      "precision: 0.610557\n",
      "recall/sensitivity(true positive rate): 0.348510\n",
      "spcificity(true negative rate): 0.778715\n",
      "false positive rate (FPR): 0.221285\n",
      "ROC_AUC_score: 0.563613\n"
     ]
    }
   ],
   "source": [
    "# evaluate test data\n",
    "evaluation(yuptest,Xuptest,models_nb_up[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "cross_validate_run: 0\n",
      "f1_socre: 0.863352\n",
      "precision: 0.844139\n",
      "recall/sensitivity(true positive rate): 0.883459\n",
      "spcificity(true negative rate): 0.836992\n",
      "false positive rate (FPR): 0.163008\n",
      "ROC_AUC_score: 0.860225\n",
      "cross_validate_run: 1\n",
      "f1_socre: 0.867468\n",
      "precision: 0.847941\n",
      "recall/sensitivity(true positive rate): 0.887916\n",
      "spcificity(true negative rate): 0.839648\n",
      "false positive rate (FPR): 0.160352\n",
      "ROC_AUC_score: 0.863782\n",
      "cross_validate_run: 2\n",
      "f1_socre: 0.864715\n",
      "precision: 0.843540\n",
      "recall/sensitivity(true positive rate): 0.886980\n",
      "spcificity(true negative rate): 0.835592\n",
      "false positive rate (FPR): 0.164408\n",
      "ROC_AUC_score: 0.861286\n",
      "cross_validate_run: 3\n",
      "f1_socre: 0.867377\n",
      "precision: 0.846337\n",
      "recall/sensitivity(true positive rate): 0.889489\n",
      "spcificity(true negative rate): 0.838682\n",
      "false positive rate (FPR): 0.161318\n",
      "ROC_AUC_score: 0.864086\n"
     ]
    }
   ],
   "source": [
    "# xgboost with deeper tree\n",
    "model4 = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "models_xgb_up = cv(Xuptrain,yuptrain,model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_socre: 0.865567\n",
      "precision: 0.844179\n",
      "recall/sensitivity(true positive rate): 0.888068\n",
      "spcificity(true negative rate): 0.836824\n",
      "false positive rate (FPR): 0.163176\n",
      "ROC_AUC_score: 0.862446\n"
     ]
    }
   ],
   "source": [
    "# evaluate test data\n",
    "evaluation(yuptest,Xuptest,models_xgb_up[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so far the best model\n",
    "pickle.dump(models_xgb_up[1],open(\"Models/xgb_up.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=2, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "cross_validate_run: 0\n",
      "f1_socre: 0.860507\n",
      "precision: 0.776583\n",
      "recall/sensitivity(true positive rate): 0.964767\n",
      "spcificity(true negative rate): 0.722635\n",
      "false positive rate (FPR): 0.277365\n",
      "ROC_AUC_score: 0.843701\n",
      "cross_validate_run: 1\n",
      "f1_socre: 0.861546\n",
      "precision: 0.778879\n",
      "recall/sensitivity(true positive rate): 0.963845\n",
      "spcificity(true negative rate): 0.724435\n",
      "false positive rate (FPR): 0.275565\n",
      "ROC_AUC_score: 0.844140\n",
      "cross_validate_run: 2\n",
      "f1_socre: 0.859100\n",
      "precision: 0.774078\n",
      "recall/sensitivity(true positive rate): 0.965103\n",
      "spcificity(true negative rate): 0.718515\n",
      "false positive rate (FPR): 0.281485\n",
      "ROC_AUC_score: 0.841809\n",
      "cross_validate_run: 3\n",
      "f1_socre: 0.860642\n",
      "precision: 0.776929\n",
      "recall/sensitivity(true positive rate): 0.964573\n",
      "spcificity(true negative rate): 0.723362\n",
      "false positive rate (FPR): 0.276638\n",
      "ROC_AUC_score: 0.843968\n"
     ]
    }
   ],
   "source": [
    "# further try to upscale weight of positive class\n",
    "model5 = model4 = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=2, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "models2_xgb_up = cv(Xuptrain,yuptrain,model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_socre: 0.860992\n",
      "precision: 0.777818\n",
      "recall/sensitivity(true positive rate): 0.964083\n",
      "spcificity(true negative rate): 0.725865\n",
      "false positive rate (FPR): 0.274135\n",
      "ROC_AUC_score: 0.844974\n"
     ]
    }
   ],
   "source": [
    "# evaluate test data\n",
    "evaluation(yuptest,Xuptest,models2_xgb_up[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so far the best model\n",
    "pickle.dump(models2_xgb_up[2],open(\"Models/xgb_up_scaled.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
